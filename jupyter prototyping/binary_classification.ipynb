{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: only the \"binary\" dataset is used in the  notebook, extension to the \"multi\" dataset is done after converting to a Python project.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_binary = pd.read_csv(\"../data/binary/X_train.csv\", header=None)\n",
    "y_train_binary = pd.read_csv(\"../data/binary/Y_train.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data cleaning & create new input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Data Visualisation & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62210, 964)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_binary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Training data summary:\n",
    "* There are 62,210 rows (images)\n",
    "* There are 964 columns (feature):\n",
    "    * first 900 columns = **HoG (Histogram of oriented Gradients)** extracted from the image (10×10 px cells, 9 orientations, 2×2 blocks).\n",
    "    * next 16 columns drawn from a **normal distribution** (µ = 0.5, σ = 2)\n",
    "    * last 48 columns correspond to 3 **colour histograms** extracted from the same image, one for each channel (RGB), with 16 bins per channel.\n",
    "\n",
    "They are split into 3 different sets for further analysis and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_HoG = X_train_binary.iloc[:, :900]\n",
    "X_train_normal_dist = X_train_binary.iloc[:, 900:916]\n",
    "X_train_colour_hists = X_train_binary.iloc[:, 916:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. HoG (Histogram of oriented Gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>890</th>\n",
       "      <th>891</th>\n",
       "      <th>892</th>\n",
       "      <th>893</th>\n",
       "      <th>894</th>\n",
       "      <th>895</th>\n",
       "      <th>896</th>\n",
       "      <th>897</th>\n",
       "      <th>898</th>\n",
       "      <th>899</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.108247</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>0.006292</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>0.125419</td>\n",
       "      <td>0.211368</td>\n",
       "      <td>0.308308</td>\n",
       "      <td>0.308308</td>\n",
       "      <td>0.047714</td>\n",
       "      <td>0.147246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>0.231606</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>0.111093</td>\n",
       "      <td>0.036183</td>\n",
       "      <td>0.151264</td>\n",
       "      <td>0.166743</td>\n",
       "      <td>0.216403</td>\n",
       "      <td>0.231606</td>\n",
       "      <td>0.072554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.245888</td>\n",
       "      <td>0.057265</td>\n",
       "      <td>0.054288</td>\n",
       "      <td>0.073985</td>\n",
       "      <td>0.245888</td>\n",
       "      <td>0.143398</td>\n",
       "      <td>0.113087</td>\n",
       "      <td>0.208721</td>\n",
       "      <td>0.173131</td>\n",
       "      <td>0.245888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018032</td>\n",
       "      <td>0.204783</td>\n",
       "      <td>0.059727</td>\n",
       "      <td>0.248219</td>\n",
       "      <td>0.248219</td>\n",
       "      <td>0.248219</td>\n",
       "      <td>0.121050</td>\n",
       "      <td>0.067763</td>\n",
       "      <td>0.037096</td>\n",
       "      <td>0.025164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.218803</td>\n",
       "      <td>0.107196</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>0.108894</td>\n",
       "      <td>0.143207</td>\n",
       "      <td>0.079305</td>\n",
       "      <td>0.068837</td>\n",
       "      <td>0.147177</td>\n",
       "      <td>0.089514</td>\n",
       "      <td>0.166596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232862</td>\n",
       "      <td>0.232918</td>\n",
       "      <td>0.048630</td>\n",
       "      <td>0.105441</td>\n",
       "      <td>0.028698</td>\n",
       "      <td>0.191464</td>\n",
       "      <td>0.218813</td>\n",
       "      <td>0.232918</td>\n",
       "      <td>0.232918</td>\n",
       "      <td>0.092948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.199052</td>\n",
       "      <td>0.099943</td>\n",
       "      <td>0.109036</td>\n",
       "      <td>0.095986</td>\n",
       "      <td>0.218288</td>\n",
       "      <td>0.205510</td>\n",
       "      <td>0.218288</td>\n",
       "      <td>0.113477</td>\n",
       "      <td>0.128925</td>\n",
       "      <td>0.218288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161302</td>\n",
       "      <td>0.234259</td>\n",
       "      <td>0.134242</td>\n",
       "      <td>0.185844</td>\n",
       "      <td>0.164967</td>\n",
       "      <td>0.234259</td>\n",
       "      <td>0.064108</td>\n",
       "      <td>0.043844</td>\n",
       "      <td>0.234259</td>\n",
       "      <td>0.119083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234368</td>\n",
       "      <td>0.163826</td>\n",
       "      <td>0.135215</td>\n",
       "      <td>0.234368</td>\n",
       "      <td>0.219650</td>\n",
       "      <td>0.100049</td>\n",
       "      <td>0.056125</td>\n",
       "      <td>0.065694</td>\n",
       "      <td>0.148874</td>\n",
       "      <td>0.234368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243317</td>\n",
       "      <td>0.243317</td>\n",
       "      <td>0.047693</td>\n",
       "      <td>0.084939</td>\n",
       "      <td>0.123729</td>\n",
       "      <td>0.113036</td>\n",
       "      <td>0.243317</td>\n",
       "      <td>0.194783</td>\n",
       "      <td>0.243317</td>\n",
       "      <td>0.136803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.108247  0.004364  0.006292  0.012344  0.125419  0.211368  0.308308   \n",
       "1  0.245888  0.057265  0.054288  0.073985  0.245888  0.143398  0.113087   \n",
       "2  0.218803  0.107196  0.056075  0.108894  0.143207  0.079305  0.068837   \n",
       "3  0.199052  0.099943  0.109036  0.095986  0.218288  0.205510  0.218288   \n",
       "4  0.234368  0.163826  0.135215  0.234368  0.219650  0.100049  0.056125   \n",
       "\n",
       "        7         8         9    ...       890       891       892       893  \\\n",
       "0  0.308308  0.047714  0.147246  ...  0.086864  0.231606  0.010222  0.111093   \n",
       "1  0.208721  0.173131  0.245888  ...  0.018032  0.204783  0.059727  0.248219   \n",
       "2  0.147177  0.089514  0.166596  ...  0.232862  0.232918  0.048630  0.105441   \n",
       "3  0.113477  0.128925  0.218288  ...  0.161302  0.234259  0.134242  0.185844   \n",
       "4  0.065694  0.148874  0.234368  ...  0.243317  0.243317  0.047693  0.084939   \n",
       "\n",
       "        894       895       896       897       898       899  \n",
       "0  0.036183  0.151264  0.166743  0.216403  0.231606  0.072554  \n",
       "1  0.248219  0.248219  0.121050  0.067763  0.037096  0.025164  \n",
       "2  0.028698  0.191464  0.218813  0.232918  0.232918  0.092948  \n",
       "3  0.164967  0.234259  0.064108  0.043844  0.234259  0.119083  \n",
       "4  0.123729  0.113036  0.243317  0.194783  0.243317  0.136803  \n",
       "\n",
       "[5 rows x 900 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_HoG.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62210 entries, 0 to 62209\n",
      "Columns: 900 entries, 0 to 899\n",
      "dtypes: float64(900)\n",
      "memory usage: 427.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_HoG.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>900</th>\n",
       "      <th>901</th>\n",
       "      <th>902</th>\n",
       "      <th>903</th>\n",
       "      <th>904</th>\n",
       "      <th>905</th>\n",
       "      <th>906</th>\n",
       "      <th>907</th>\n",
       "      <th>908</th>\n",
       "      <th>909</th>\n",
       "      <th>910</th>\n",
       "      <th>911</th>\n",
       "      <th>912</th>\n",
       "      <th>913</th>\n",
       "      <th>914</th>\n",
       "      <th>915</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.280041</td>\n",
       "      <td>1.238382</td>\n",
       "      <td>2.661622</td>\n",
       "      <td>-2.942723</td>\n",
       "      <td>0.256651</td>\n",
       "      <td>-0.847558</td>\n",
       "      <td>-0.144272</td>\n",
       "      <td>-3.628990</td>\n",
       "      <td>-0.317223</td>\n",
       "      <td>2.649822</td>\n",
       "      <td>5.004708</td>\n",
       "      <td>-4.185132</td>\n",
       "      <td>-0.319661</td>\n",
       "      <td>-0.403782</td>\n",
       "      <td>0.837098</td>\n",
       "      <td>0.674467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.734251</td>\n",
       "      <td>3.321642</td>\n",
       "      <td>-1.756527</td>\n",
       "      <td>3.417488</td>\n",
       "      <td>-1.973764</td>\n",
       "      <td>-0.026902</td>\n",
       "      <td>2.733768</td>\n",
       "      <td>1.420462</td>\n",
       "      <td>0.212293</td>\n",
       "      <td>0.360131</td>\n",
       "      <td>1.912276</td>\n",
       "      <td>6.072646</td>\n",
       "      <td>-3.138425</td>\n",
       "      <td>-1.144073</td>\n",
       "      <td>-0.793034</td>\n",
       "      <td>-2.189273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.218798</td>\n",
       "      <td>-0.706921</td>\n",
       "      <td>-0.970352</td>\n",
       "      <td>1.446063</td>\n",
       "      <td>1.069938</td>\n",
       "      <td>4.533852</td>\n",
       "      <td>2.815861</td>\n",
       "      <td>-0.491769</td>\n",
       "      <td>-0.232733</td>\n",
       "      <td>1.098961</td>\n",
       "      <td>-0.329036</td>\n",
       "      <td>2.557483</td>\n",
       "      <td>-1.199582</td>\n",
       "      <td>0.998466</td>\n",
       "      <td>-1.331319</td>\n",
       "      <td>1.782689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.192398</td>\n",
       "      <td>-1.735968</td>\n",
       "      <td>2.031139</td>\n",
       "      <td>0.725424</td>\n",
       "      <td>-0.305053</td>\n",
       "      <td>-1.314722</td>\n",
       "      <td>-1.477061</td>\n",
       "      <td>3.391574</td>\n",
       "      <td>3.039285</td>\n",
       "      <td>-0.780832</td>\n",
       "      <td>0.132886</td>\n",
       "      <td>2.852817</td>\n",
       "      <td>4.059947</td>\n",
       "      <td>-0.462990</td>\n",
       "      <td>3.677201</td>\n",
       "      <td>-4.173188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.691028</td>\n",
       "      <td>-4.928038</td>\n",
       "      <td>-2.162437</td>\n",
       "      <td>1.651693</td>\n",
       "      <td>0.314290</td>\n",
       "      <td>2.053126</td>\n",
       "      <td>6.163571</td>\n",
       "      <td>1.326052</td>\n",
       "      <td>-2.152279</td>\n",
       "      <td>3.103169</td>\n",
       "      <td>-1.078835</td>\n",
       "      <td>-0.374443</td>\n",
       "      <td>1.339320</td>\n",
       "      <td>-0.335326</td>\n",
       "      <td>0.810662</td>\n",
       "      <td>-0.089223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        900       901       902       903       904       905       906  \\\n",
       "0 -1.280041  1.238382  2.661622 -2.942723  0.256651 -0.847558 -0.144272   \n",
       "1  1.734251  3.321642 -1.756527  3.417488 -1.973764 -0.026902  2.733768   \n",
       "2 -1.218798 -0.706921 -0.970352  1.446063  1.069938  4.533852  2.815861   \n",
       "3 -2.192398 -1.735968  2.031139  0.725424 -0.305053 -1.314722 -1.477061   \n",
       "4 -0.691028 -4.928038 -2.162437  1.651693  0.314290  2.053126  6.163571   \n",
       "\n",
       "        907       908       909       910       911       912       913  \\\n",
       "0 -3.628990 -0.317223  2.649822  5.004708 -4.185132 -0.319661 -0.403782   \n",
       "1  1.420462  0.212293  0.360131  1.912276  6.072646 -3.138425 -1.144073   \n",
       "2 -0.491769 -0.232733  1.098961 -0.329036  2.557483 -1.199582  0.998466   \n",
       "3  3.391574  3.039285 -0.780832  0.132886  2.852817  4.059947 -0.462990   \n",
       "4  1.326052 -2.152279  3.103169 -1.078835 -0.374443  1.339320 -0.335326   \n",
       "\n",
       "        914       915  \n",
       "0  0.837098  0.674467  \n",
       "1 -0.793034 -2.189273  \n",
       "2 -1.331319  1.782689  \n",
       "3  3.677201 -4.173188  \n",
       "4  0.810662 -0.089223  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal_dist.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62210 entries, 0 to 62209\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   900     62210 non-null  float64\n",
      " 1   901     62210 non-null  float64\n",
      " 2   902     62210 non-null  float64\n",
      " 3   903     62210 non-null  float64\n",
      " 4   904     62210 non-null  float64\n",
      " 5   905     62210 non-null  float64\n",
      " 6   906     62210 non-null  float64\n",
      " 7   907     62210 non-null  float64\n",
      " 8   908     62210 non-null  float64\n",
      " 9   909     62210 non-null  float64\n",
      " 10  910     62210 non-null  float64\n",
      " 11  911     62210 non-null  float64\n",
      " 12  912     62210 non-null  float64\n",
      " 13  913     62210 non-null  float64\n",
      " 14  914     62210 non-null  float64\n",
      " 15  915     62210 non-null  float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 7.6 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_normal_dist.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Colour histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>916</th>\n",
       "      <th>917</th>\n",
       "      <th>918</th>\n",
       "      <th>919</th>\n",
       "      <th>920</th>\n",
       "      <th>921</th>\n",
       "      <th>922</th>\n",
       "      <th>923</th>\n",
       "      <th>924</th>\n",
       "      <th>925</th>\n",
       "      <th>...</th>\n",
       "      <th>954</th>\n",
       "      <th>955</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>958</th>\n",
       "      <th>959</th>\n",
       "      <th>960</th>\n",
       "      <th>961</th>\n",
       "      <th>962</th>\n",
       "      <th>963</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>129.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>338.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>...</td>\n",
       "      <td>440.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>871.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>...</td>\n",
       "      <td>166.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     916    917    918    919     920    921    922    923    924     925  \\\n",
       "0  570.0  957.0  448.0  214.0   179.0  227.0  243.0  197.0  152.0    95.0   \n",
       "1   26.0   99.0  263.0  450.0   656.0  552.0  525.0  349.0  252.0   186.0   \n",
       "2    9.0   42.0  143.0  324.0   668.0  494.0  447.0  407.0  368.0   344.0   \n",
       "3   11.0   83.0  104.0  486.0  1003.0  545.0  724.0  191.0  199.0    88.0   \n",
       "4    4.0   37.0   69.0  112.0   159.0  101.0  145.0  187.0  707.0  1299.0   \n",
       "\n",
       "   ...    954    955    956     957    958    959    960   961   962   963  \n",
       "0  ...  129.0  160.0  264.0   233.0  144.0  121.0  117.0  80.0  35.0  23.0  \n",
       "1  ...  338.0  277.0  199.0   122.0   94.0   26.0   11.0   8.0   3.0   1.0  \n",
       "2  ...  440.0  351.0  218.0   124.0   63.0   21.0    9.0   7.0   6.0   3.0  \n",
       "3  ...  871.0  427.0  578.0   292.0   75.0  102.0   81.0  30.0  33.0  10.0  \n",
       "4  ...  166.0  285.0  605.0  1011.0  822.0  192.0   39.0  14.0   8.0   5.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_colour_hists.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62210 entries, 0 to 62209\n",
      "Data columns (total 48 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   916     62210 non-null  float64\n",
      " 1   917     62210 non-null  float64\n",
      " 2   918     62210 non-null  float64\n",
      " 3   919     62210 non-null  float64\n",
      " 4   920     62210 non-null  float64\n",
      " 5   921     62210 non-null  float64\n",
      " 6   922     62210 non-null  float64\n",
      " 7   923     62210 non-null  float64\n",
      " 8   924     62210 non-null  float64\n",
      " 9   925     62210 non-null  float64\n",
      " 10  926     62210 non-null  float64\n",
      " 11  927     62210 non-null  float64\n",
      " 12  928     62210 non-null  float64\n",
      " 13  929     62210 non-null  float64\n",
      " 14  930     62210 non-null  float64\n",
      " 15  931     62210 non-null  float64\n",
      " 16  932     62210 non-null  float64\n",
      " 17  933     62210 non-null  float64\n",
      " 18  934     62210 non-null  float64\n",
      " 19  935     62210 non-null  float64\n",
      " 20  936     62210 non-null  float64\n",
      " 21  937     62210 non-null  float64\n",
      " 22  938     62210 non-null  float64\n",
      " 23  939     62210 non-null  float64\n",
      " 24  940     62210 non-null  float64\n",
      " 25  941     62210 non-null  float64\n",
      " 26  942     62210 non-null  float64\n",
      " 27  943     62210 non-null  float64\n",
      " 28  944     62210 non-null  float64\n",
      " 29  945     62210 non-null  float64\n",
      " 30  946     62210 non-null  float64\n",
      " 31  947     62210 non-null  float64\n",
      " 32  948     62210 non-null  float64\n",
      " 33  949     62210 non-null  float64\n",
      " 34  950     62210 non-null  float64\n",
      " 35  951     62210 non-null  float64\n",
      " 36  952     62210 non-null  float64\n",
      " 37  953     62210 non-null  float64\n",
      " 38  954     62210 non-null  float64\n",
      " 39  955     62210 non-null  float64\n",
      " 40  956     62210 non-null  float64\n",
      " 41  957     62210 non-null  float64\n",
      " 42  958     62210 non-null  float64\n",
      " 43  959     62210 non-null  float64\n",
      " 44  960     62210 non-null  float64\n",
      " 45  961     62210 non-null  float64\n",
      " 46  962     62210 non-null  float64\n",
      " 47  963     62210 non-null  float64\n",
      "dtypes: float64(48)\n",
      "memory usage: 22.8 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_colour_hists.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Class ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49768 entries, 5149 to 12116\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       49768 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 777.6+ KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the occurences (and relative % distribution) of each class in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seal': {'occurences': 7778, 'distribution': 0.12503},\n",
       " 'background': {'occurences': 54432, 'distribution': 0.87497}}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_occurences = y_train_load.shape[0]\n",
    "class_distribution = {\n",
    "    'seal': {\n",
    "        'occurences': y_train_load[0].value_counts()[\"seal\"],\n",
    "        'distribution': round(y_train_load[0].value_counts()[\"seal\"] / total_occurences, 5)\n",
    "    },\n",
    "    'background': {\n",
    "        'occurences': y_train_load[0].value_counts()[\"background\"],\n",
    "        'distribution': round(y_train_load[0].value_counts()[\"background\"] / total_occurences, 5)\n",
    "    }\n",
    "}\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of classes in the training set in a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data preparation for bar chart.\n",
    "data = [class_distribution['seal']['occurences'], class_distribution['background']['occurences']]\n",
    "value_labels = [class_distribution['seal']['distribution'], class_distribution['background']['distribution']]\n",
    "x_axis_labels = [\"seal\", \"background\"]\n",
    "\n",
    "# Matplot lib bar chart.\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.xticks(range(len(data)), labels)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Occurences\")\n",
    "plt.title(\"Binary dataset: Class frequency occurences & distribution\")\n",
    "plt.bar(labels, data)\n",
    "plt.grid(color='#95a5a6', linestyle='-', linewidth=1, axis='y', alpha=0.5)\n",
    "\n",
    "# Add value labels for each bar.\n",
    "for a,b in zip(labels, data):\n",
    "    plt.text(a, b, \"{}%\".format(str(round(class_distribution[a]['distribution'], 2))))\n",
    "    \n",
    "# Save and display chart.\n",
    "plt.savefig(\"binary_class_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Prepare inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Validation data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is already split into training and testing sets. To avoid data snooping, the testing set is ignored until the evaluation section.\n",
    "\n",
    "However, the training set is further split between a training and a validation set to evaluate its performance during training.\n",
    "\n",
    "A randomised 80%/20% split is used rather than stratified sampling because the dataset is large enough. According to Hands-On ML, if the dataset is large enough, the risk of introducing sampling bias is low (he mentions a set of 1,000 rows, whereas ours has 62210 rows).\n",
    "\n",
    "The random number generator's seed is set at a fixed value to ensure that it always generates the same shuffle indices when re-running the code, ensuring reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_binary, y_train_binary, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm new training dataset sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set split:\n",
      "Train set size = (49768, 964)\n",
      "Validation set size = (12442, 964)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set split:\\nTrain set size = {}\\nValidation set size = {}\".format(X_train.shape, X_validate.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert class ID output to boolean format for logistic regression (True if it's a \"seal\", False if it's a \"background\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_seal = (y_train == \"seal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts 5/6: Select & train classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_classifier = SGDClassifier(max_iter=1000, tol=1e-3, random_state=RANDOM_SEED)\n",
    "sgd_classifier.fit(X_train, y_train.values.ravel())\n",
    "# use values to get the values in an array, so a shape of (n,1) and then ravel() tothe convert that array shape to (n, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = sgd_classifier.predict(X_train)\n",
    "confusion_matrix(y_train, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Evaluating & comparing models performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"../data/binary/X_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8: Critical discussion of the results, approach and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
